{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MR-Longitudinal Radiomics\n",
    "### Radiomics pipeline created for longitudinal images collected at subsequent fractions of treatment.\n",
    "##### Full model: Feature Extraction, Feature Reduction via volume correlation & test-retest stability, Feature Selection via Euclidean distance between feature pair trajectories and hierachical clustering.\n",
    "##### Compares the results of the longitudinal model with a standard delta-radiomics approach to illustrate the importance of accounting for the full feature trajectory over treatment.\n",
    "\n",
    "###\n",
    "#### Below specify certain variables and options for customising the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Specify the output path\n",
    "# specify the tag to use - could be anything, helps to identify the output if running multiple models\n",
    "# default is \"Test\"\n",
    "tag = \"Long-Test\"\n",
    "# output_path = \"C:/Users/b01297ar/Documents/ProstateMRL-local/ProstateMRL-Radiomics/ReleaseCode/Output/\" + tag + \"/\"\n",
    "cwd = os.getcwd()\n",
    "output_path = cwd + \"/Output/\" \n",
    "if os.path.exists(output_path) == False:\n",
    "        os.mkdir(output_path)\n",
    "if os.path.exists(output_path + tag) == False:\n",
    "    os.mkdir(output_path + tag)\n",
    "    os.mkdir(output_path + tag + \"/Features/\")\n",
    "    os.mkdir(output_path + tag + \"/Extraction/\")\n",
    "    os.mkdir(output_path + tag + \"/Plots/\")\n",
    "output_path = cwd + \"/Output/\" + tag + \"/\"\n",
    "\n",
    "# specify if you want to compare to a delta model\n",
    "# default is False\n",
    "Delta_Model = False\n",
    "\n",
    "# Specify if you want to visualise the results in plots\n",
    "# default is False, can specify at given stages below if you want to visualise\n",
    "plot = False\n",
    "\n",
    "# Specify if you want to extract Features\n",
    "# default is False, option to do so is below\n",
    "# If features are already extracted, set to false and provide the path to the extracted features below\n",
    "extract = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# MS_df = pd.read_csv(\"/data/t/Aaron/ProstateMRL/Data/MSContours.csv\", sep=\",\", encoding='cp1252')\n",
    "# MS_df[\"PatID\"] = MS_df[\"PatID\"].astype(str)\n",
    "# MS_pats = MS_df[\"PatID\"].unique()\n",
    "\n",
    "# cwd = os.getcwd()\n",
    "\n",
    "# key_df = pd.read_csv(\"/data/t/Aaron/ProstateMRL/Data/LimbusKey.csv\")\n",
    "# key_df[\"Contour\"] = \"RP\"\n",
    "# key_df[\"PatID\"] = key_df[\"PatID\"].astype(str)\n",
    "\n",
    "# # if patid in MS_pats and key_df[\"PatID\"] == patid change contour to MS\n",
    "# for i in range(len(key_df)):\n",
    "#     if key_df[\"PatID\"][i] in MS_pats:\n",
    "#         key_df[\"Contour\"][i] = \"MS\"\n",
    "\n",
    "# key_df[\"ContourType\"] = \"Manual\"\n",
    "# key_df[\"ImagePath\"] = key_df[\"ImagePath\"].str.replace(\"\\\\\", \"/\")\n",
    "# key_df[\"ImagePath\"] = key_df[\"ImagePath\"].str.replace(\"D:/data/\", \"/data/t/\")\n",
    "# key_df[\"ImagePath\"] = key_df[\"ImagePath\"].str.replace(\"HM-FSTP\", \"HM-FS\")\n",
    "\n",
    "# key_df[\"MaskPath\"] = key_df[\"ImagePath\"].str.replace(\"HM-FS\", \"Masks\")\n",
    "\n",
    "# # replace masks.nii with mask value for that patient\n",
    "# for i in range(len(key_df)):\n",
    "#     key_df[\"MaskPath\"][i] = key_df[\"MaskPath\"][i].replace(\"Masks.nii\", key_df[\"Contour\"][i] + \"_pros.nii\")\n",
    "\n",
    "# #key_df[\"MaskPath\"] = key_df[\"MaskPath\"].str.replace(\"_Masks.nii\", \"_\" + )\n",
    "# key_df = key_df[['PatID', 'Fraction', 'Scan','Contour', 'ContourType', 'ImagePath', 'MaskPath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_df.to_csv(cwd + \"/Input/Default/PepKey_Man.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fix mask and image paths\n",
    "\n",
    "# key_df = pd.read_csv(cwd + \"/Input/Default/PepKey_Man.csv\")\n",
    "\n",
    "# for i in range(len(key_df)):\n",
    "#     # some patids are missing a 0 at the start of the paths\n",
    "#     path_ID = key_df[\"ImagePath\"][i].split(\"/\")[6]\n",
    "#     mask_file = key_df[\"MaskPath\"][i].split(\"/\")[-1]\n",
    "#     image_file = key_df[\"ImagePath\"][i].split(\"/\")[-1]\n",
    "#     mask_fix = mask_file.replace(mask_file.split(\"_\")[0], path_ID)\n",
    "#     image_fix = image_file.replace(image_file.split(\"_\")[0], path_ID)\n",
    "\n",
    "#     key_df[\"MaskPath\"][i] = key_df[\"MaskPath\"][i].replace(mask_file, mask_fix)\n",
    "#     key_df[\"ImagePath\"][i] = key_df[\"ImagePath\"][i].replace(image_file, image_fix)\n",
    "    \n",
    "\n",
    "# key_df.to_csv(cwd + \"/Input/Default/PepKey_Man.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limbus_df = key_df.copy()\n",
    "\n",
    "# limbus_df[\"Contour\"] = \"Limbus\"\n",
    "# limbus_df[\"ContourType\"] = \"Auto\"\n",
    "\n",
    "# for i in range(len(limbus_df)):\n",
    "#     limbus_df[\"MaskPath\"][i] = \"/data/t/prostateMR_radiomics/PatPacks/P1-LimbusMasks/\" + str(limbus_df[\"PatID\"][i]) + \"_\" + str(limbus_df[\"Fraction\"][i]) + \".nii\"\n",
    "    \n",
    "\n",
    "# limbus_df.to_csv(cwd + \"/Input/Default/PepKey_Lim.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "#### If you want to extract features, provide a csv containing the following:\n",
    "####               | PatID | Fraction | Image file | Mask Name | Mask file | \n",
    "#### Specify the root of the csv in the Input dir.\n",
    "#### Calculates features based on the parameter file specified. Default setting is currently set at PyRadiomics base extraction parameters - Fixed bin size (FBS) of 25, no resampling, no normalisation, 107 features (IBSI compliant) and no wavelet/laplacian filters applied. \n",
    "#### Features are then calculated and then saved in a new folder in the Output dir - with files in parquet format. Columns will be:\n",
    "#### PatID | Fraction | Mask | Feature | Feature Value |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions import Extraction as FE\n",
    "\n",
    "if extract == True:\n",
    "    \n",
    "    key_extraction = cwd + \"/Input/Default/PepKey_Man.csv\"\n",
    "    key_extraction = pd.read_csv(key_extraction)\n",
    "\n",
    "    extraction_path = output_path + \"/Extraction/\"\n",
    "    if not os.path.exists(extraction_path):\n",
    "        os.makedirs(extraction_path)\n",
    "\n",
    "    params_extractor = cwd + \"/Input/Default/Default_ExtractionParams.yaml\"\n",
    "\n",
    "\n",
    "    # Loop over all patients\n",
    "    print(\"Extracting features for patients...\")\n",
    "    for pat in key_extraction[\"PatID\"].unique():\n",
    "        print(\"Processing patient: \" + str(pat) + \"...\")\n",
    "\n",
    "        # Get the patient's key\n",
    "        key_pat = key_extraction[key_extraction[\"PatID\"] == pat]\n",
    "        Features_pat = pd.DataFrame()\n",
    "        # loop over all rows\n",
    "        if os.path.exists(output_path + \"/Extraction/Manual_\" + str(pat) + \"_\" + tag + \".csv\"):\n",
    "            print(\" \")\n",
    "\n",
    "        else:\n",
    "            for i, row in key_pat.iterrows():\n",
    "\n",
    "\n",
    "                PatID = row[\"PatID\"]\n",
    "                Fraction = row[\"Fraction\"]\n",
    "                Mask = row[\"Contour\"]\n",
    "                ContourType = row[\"ContourType\"]\n",
    "                ImagePath = row[\"ImagePath\"]\n",
    "                MaskPath = row[\"MaskPath\"]\n",
    "                \n",
    "                # Extract features\n",
    "                Features = FE.ExtractFeatures(PatID, Fraction, Mask, ContourType, ImagePath, MaskPath, params_extractor)\n",
    "\n",
    "                Features_pat = Features_pat.append(Features)\n",
    "            \n",
    "                \n",
    "            Features_pat.to_csv(output_path + \"/Extraction/\" + ContourType + \"_\" + str(pat) + \"_\" + tag + \".csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once all features have been extracted, combine in to one dataframe\n",
    "#### Or\n",
    "#### Specify the path of the feature values. \n",
    "##### Default is to read in a parquet file (smaller file sizes - so quicker), make sure to change to pd.read_csv if reading in csv and change path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all patients\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "files = os.listdir(output_path + \"/Extraction/\")\n",
    "for file in files:\n",
    "    df_pat = pd.read_csv(output_path + \"/Extraction/\" + file)\n",
    "    df_all = df_all.append(df_pat)\n",
    "    \n",
    "\n",
    "    # Save the features to parquet\n",
    "if os.path.exists(output_path + \"/Features/\") == False:\n",
    "    os.mkdir(output_path + \"/Features/\")   \n",
    "df_all.to_csv(output_path + \"/Features/Features_\" + tag + \".csv\")\n",
    "\n",
    "# Specify the path to the features  \n",
    "# else:\n",
    "#     # Features_all = pd.read_parquet(output_path + \"/Features/Features_\" + tag + \".parquet\")    \n",
    "#     # Features_all = pd.read_csv(\"E:/Aaron/ProstateMRL/Data/Paper1/HM-FS/Features/Longitudinal_All_fts_Baseline.csv\")\n",
    "#     # df_all = pd.read_csv(\"C:/Users/b01297ar/Documents/ProstateMRL-local/ProstateMRL-Radiomics/Data/FeatureData/Longitudinal_All_fts_Baseline.csv\")\n",
    "#     df_all = pd.read_csv(cwd + \"/Output/\" + tag + \"/Features/Features_Baseline.csv\")\n",
    "# # df_all.drop([\"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "# df_all = pd.read_csv(cwd + \"/Output/\" + tag + \"/Features/Features_\" + tag + \".csv\")\n",
    "# df_all.drop([\"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "df_all[\"Feature\"] = df_all[\"Feature\"].str.replace(\"original_\", \"\")\n",
    "df_all = df_all[~df_all[\"Feature\"].isin([\"firstorder_Minimum\", \"firstorder_Maximum\"])]\n",
    "df_all.head()\n",
    "\n",
    "# df_ICC = pd.read_csv(\"C:/Users/b01297ar/Documents/ProstateMRL-local/ProstateMRL-Radiomics/Data/FeatureData/Longitudinal_Limbus_fts_Baseline.csv\")\n",
    "# df_ICC.drop([\"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "# remove first order min and max\n",
    "\n",
    "df_man = df_all.loc[df_all[\"ContourType\"] == \"Manual\"]\n",
    "df_limbus = df_all.loc[df_all[\"Contour\"] == \"Limbus\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction\n",
    "#### Due to the high dimensionnality of radiomics values, it is vital that some of the features are removed if they offer no unique information. \n",
    "#### Since features are calculated by applying different formulas to images, many of these formulas are similar and so some features can be quite similar. We aim to remove all redundant features - redundant features in this model are those that are strongly correlated to volume, Spearman Rank coefficient rho > 0.6 and unstable due to contour differences, as measured by an ICC value < 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions import Reduction as FR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume Correlation\n",
    "#### Previous studies have shown that radiomic feature values have a strong correlation with the volume of the mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import HTML, display\n",
    "gif_path = cwd + \"/NotebookFigures/VolCorr.gif\"\n",
    "b64 = base64.b64encode(open(gif_path, 'rb').read()).decode('ascii')\n",
    "display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" width=\"500\" height=\"400\" align = \"center\" >'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Volume Correlation\n",
      "Correlating features to volume...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:00<00:00, 755.17it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 674.06it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 754.53it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 754.14it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 758.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume redundant features: 22/107\n",
      "------------------------------\n",
      "Plotting volume correlation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:49<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "------------------------------\n",
      "Volume Correlation\n",
      "Correlating features to volume...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:00<00:00, 668.91it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 661.63it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 660.49it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 669.10it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 617.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume redundant features: 26/107\n",
      "------------------------------\n",
      "Plotting volume correlation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:49<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate volume correlation\n",
    "from Functions import Reduction as FR\n",
    "import pandas as pd\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "df_all = pd.read_csv(cwd + \"/Output/Long-Test/Features/Features_Long-Test.csv\")\n",
    "output_path = cwd + \"/Output/Long-Test/\"\n",
    "df_all[\"Feature\"] = df_all[\"Feature\"].str.replace(\"original_\", \"\")\n",
    "\n",
    "df_man = df_all.loc[df_all[\"ContourType\"] == \"Manual\"]\n",
    "df_limbus = df_all.loc[df_all[\"Contour\"] == \"Limbus\"]\n",
    "FR.Volume(df_man, output_path, plot=True)\n",
    "FR.Volume(df_limbus, output_path, plot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICC Stability\n",
    "#### Intra-class correlation coefficient is used as a statistical measure of how much two observed quantities within a group tend to agree with each other. \n",
    "#### Been used widely within radiomics studies as a test-retest stability measure between two delineations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Stability Test\n",
      "Calculating ICC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:03<00:00, 29.71it/s]\n",
      "100%|██████████| 107/107 [00:03<00:00, 29.37it/s]\n",
      "100%|██████████| 107/107 [00:03<00:00, 30.02it/s]\n",
      "100%|██████████| 107/107 [00:03<00:00, 30.16it/s]\n",
      "100%|██████████| 107/107 [00:03<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICC redudant features: 17/107\n",
      "------------------------------\n",
      "Plotting ICC Values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:38<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Functions import Reduction as FR\n",
    "import pandas as pd\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "df_all = pd.read_csv(cwd + \"/Output/Long-Test/Features/Features_Long-Test.csv\")\n",
    "output_path = cwd + \"/Output/Long-Test/\"\n",
    "FR.ICC(df_all, output_path, plot=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove redundant features\n",
    "\n",
    "#### Still need to do further feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Removing redundant features...\n",
      "Number of features removed: 36\n",
      "Number of features remaining: 71\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_all = FR.RemoveFts(df_all, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering I - Distance between Feature Trajectories\n",
    "#### Calculate the Euclidean distance between feature pairs.\n",
    "#### Distance values can then be used to visualise the relationship between features.\n",
    "#### Can also be used to group features together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Euclidean distance between feature pair trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:49<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from Functions import Clustering as Cl\n",
    "Cl.DistanceMatrix(df_all, output_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering II - Grouping Features\n",
    "#### Hierarchical clustering using SciPy\n",
    "####   - Weighted linkage (Refers to the algorithm by which clusters are formed)\n",
    "####   - Starting T-val = 2 (Refers to the threshold value for which to go to a different cluster, i.e. how far away a value is to a cluster before a new cluster is created/put in another cluster.)\n",
    "##### Clusters with < 3 features discarded as deemed too unstable.\n",
    "##### Clusters with > 10 features re-clustered to subclusters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Clustering Feature Trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 28.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Cl.ClusterFeatures(df_all, output_path, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering III - Feature Selection\n",
    "#### Cross-correlation value between feature trajectories within each cluster performed to determine most “representative” feature\n",
    "####    - Highest mean cross-correlation passed through.\n",
    "####    - Top 20% of features.\n",
    "#### Each patient passes through a set of features.\n",
    "#### Features then tallied up and the top 10 ranked features are selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Feature Selection\n",
      "Calculating Cross-Correlation values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Selected Features: \n",
      "glcm_JointEntropy\n",
      "firstorder_Uniformity\n",
      "gldm_GrayLevelVariance\n",
      "gldm_LargeDependenceEmphasis\n",
      "firstorder_RootMeanSquared\n",
      "firstorder_Variance\n",
      "glrlm_ShortRunEmphasis\n",
      "glcm_Correlation\n",
      "glcm_Idn\n",
      "glcm_DifferenceAverage\n",
      "glcm_DifferenceVariance\n",
      "gldm_SmallDependenceEmphasis\n",
      "------------------------------\n",
      "Number of Selected Features: 12\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Cl.FeatureSelection(df_all, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in both: 1\n",
      "glrlm_GrayLevelVariance\n"
     ]
    }
   ],
   "source": [
    "L_fts = pd.read_csv(output_path + \"/Features/Features_Selected.csv\")\n",
    "D_fts = pd.read_csv(\"/home/arn/Radiomics/Paper1-Release/Output/Delta-Test/Features/Features_Selected.csv\")\n",
    "\n",
    "L_fts = L_fts[\"Feature\"].values\n",
    "D_fts = D_fts[\"Feature\"].values\n",
    "\n",
    "# get the features that are in both\n",
    "fts = [x for x in L_fts if x in D_fts]\n",
    "\n",
    "print(\"Number of features in both: \" + str(len(fts)))\n",
    "for ft in fts:\n",
    "    print(ft)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd78d60c78312e2835784dd761e640488478adfd13dfcaae9b4668852672f22d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('py-envs': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
