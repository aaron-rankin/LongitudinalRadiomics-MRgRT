{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_root = \"E:/Aaron/ProstateMRL/Data/Paper2/Extraction/\"\n",
    "out_root = \"E:/Aaron/ProstateMRL/Data/Paper2/Features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_key = pd.DataFrame()\n",
    "\n",
    "treatment_root = \"E:/prostateMR_radiomics/patientData/\"\n",
    "\n",
    "for treatment in os.listdir(treatment_root):\n",
    "    temp = {}\n",
    "    temp['Folder'] = treatment\n",
    "    temp['Treatment'] = treatment.split(\"_\")[0]\n",
    "\n",
    "    for pat in os.listdir(treatment_root + treatment):\n",
    "        temp[\"PatID\"] = pat\n",
    "        df_key = df_key.append(temp, ignore_index=True)\n",
    "\n",
    "df_key.to_csv(out_root + \"/df_treatmentkey.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "folders = os.listdir(data_root)\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(data_root + folder)\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_parquet(data_root + folder + '/' + file)\n",
    "        df[\"Region\"] = folder\n",
    "        df[\"PatID\"] = file.split(\"_\")[0]\n",
    "        \n",
    "        # pivot wide to long\n",
    "        df.rename(columns={\"Unnamed: 0\": \"Feature\"}, inplace=True)\n",
    "        # drop rows with diagnotix features\n",
    "        df = df[~df[\"Feature\"].str.contains(\"diagnostic\")]  \n",
    "        dates = df.loc[0,:][1:6].values\n",
    "        df = df.iloc[1:,:]\n",
    "\n",
    "        # pivot wide to long\n",
    "        df = df.melt(id_vars=[\"PatID\", \"Region\", \"Feature\"])\n",
    "        df.rename(columns={\"variable\": \"Fraction\"}, inplace=True)\n",
    "        df[\"Fraction\"] = df[\"Fraction\"].str.replace(folder + \"_\", \"\").astype(int)\n",
    "        df[\"Date\"] = df[\"Fraction\"].map(dict(zip(range(1,6), dates)))\n",
    "        \n",
    "        df[\"Treatment\"] = df[\"PatID\"].map(dict(zip(df_key[\"PatID\"], df_key[\"Treatment\"])))\n",
    "        df[\"Folder\"] = df[\"PatID\"].map(dict(zip(df_key[\"PatID\"], df_key[\"Folder\"])))\n",
    "\n",
    "        # reorder columns\n",
    "        df = df[[\"PatID\", \"Treatment\", \"Folder\", \"Region\", \"Fraction\", \"Date\",\"Feature\", \"value\"]]\n",
    "\n",
    "        df_all = df_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"Feature\"] = df_all[\"Feature\"].str.replace(\"original_\", \"\")\n",
    "df_all[\"FeatureGroup\"] = df_all[\"Feature\"].str.split(\"_\", expand=True)[0]\n",
    "df_all.rename(columns={\"value\": \"FeatureValue\"}, inplace=True)\n",
    "df_all[\"FeatureValue\"] = df_all[\"FeatureValue\"].astype(float)\n",
    "\n",
    "\n",
    "df_all.to_parquet(out_root + \"/df_all.parquet\")\n",
    "\n",
    "df_SABR = df_all[df_all[\"Treatment\"] == \"SABR\"]\n",
    "df_SABR.to_parquet(out_root + \"/df_SABR.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SABR = pd.read_parquet(out_root + \"/df_SABR.parquet\")\n",
    "\n",
    "PatIDs = df_SABR[\"PatID\"].unique()  \n",
    "\n",
    "# shape features will not change over time since they are extracted from the same mask\n",
    "df_vol = df_SABR[df_SABR[\"Feature\"] == \"shape_MeshVolume\"]\n",
    "df_vol = df_vol[[\"PatID\", \"Region\", \"FeatureValue\"]]\n",
    "df_vol.rename(columns={\"FeatureValue\": \"Volume\"}, inplace=True)\n",
    "df_vol.drop_duplicates(inplace=True)\n",
    "df_vol[\"Volume\"] = df_vol[\"Volume\"].astype(float)\n",
    "df_vol.to_parquet(out_root + \"/df_vol.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SABR = df_SABR[df_SABR[\"Region\"].isin([\"dipl\", \"normProstate\"]) ]\n",
    "df_SABR = df_SABR[[\"PatID\", \"Fraction\", \"Region\", \"Feature\", \"FeatureValue\"]]\n",
    "\n",
    "# split into dipl and normProstate\n",
    "df_dipl = df_SABR[df_SABR[\"Region\"] == \"dipl\"]\n",
    "df_normProstate = df_SABR[df_SABR[\"Region\"] == \"normProstate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# plot random features over time\n",
    "features = df_SABR[\"Feature\"].unique()\n",
    "features = np.random.choice(features, 10, replace=False)\n",
    "\n",
    "for feature in features:\n",
    "    df_ft = df_SABR[df_SABR[\"Feature\"] == feature]\n",
    "\n",
    "    # subplots\n",
    "    # make subplot for each patient\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.set_context(\"paper\", font_scale=1.5)\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(15, 15), sharey=False)\n",
    "    fig.suptitle(feature, fontsize=20)\n",
    "    # chnage stye of plots\n",
    "    \n",
    "    for i, pat in enumerate(PatIDs):\n",
    "        df_pat = df_ft[df_ft[\"PatID\"] == pat]\n",
    "        df_dipl = df_pat[df_pat[\"Region\"] == \"dipl\"]\n",
    "        df_norm = df_pat[df_pat[\"Region\"] == \"normProstate\"]\n",
    "\n",
    "        df_pat = df_pat.sort_values(by=\"Fraction\")\n",
    "        axs[i//5, i%5].plot(df_dipl[\"Fraction\"], df_dipl[\"FeatureValue\"], marker=\"o\", label=\"dipl\", color=\"blue\")\n",
    "        axs[i//5, i%5].plot(df_norm[\"Fraction\"], df_norm[\"FeatureValue\"], marker=\"o\", label=\"normProstate\", color=\"orange\")\n",
    "\n",
    "        axs[i//5, i%5].set_title(pat)\n",
    "        axs[i//5, i%5].set_xticks(range(1,6))\n",
    "        #axs[i//5, i%5].set_xticklabels(df_pat[\"Date\"].values, rotation=45)\n",
    "        #axs[i//5, i%5].set_ylim([0, df_pat[\"FeatureValue\"].max() * 1.1])\n",
    "        axs[i//5, i%5].set_xlim([0.5, 5.5])\n",
    "        axs[i//5, i%5].set_xlabel(\"Fraction\")\n",
    "        axs[i//5, i%5].set_ylabel(\"Feature Value\")\n",
    "\n",
    "    # remove empty subplots\n",
    "    for i in range(len(PatIDs), 20):\n",
    "        axs[i//5, i%5].axis('off')\n",
    "    \n",
    "    # add legend in to empty subplot (bottom right)\n",
    "    # Create a legend for the first line.\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', label='dipl', markerfacecolor='blue', markersize=10),\n",
    "                          Line2D([0], [0], marker='o', color='w', label='normProstate', markerfacecolor='orange', markersize=10)]\n",
    "    \n",
    "    \n",
    "    axs[3, 4].legend(handles=legend_elements, loc='center', fontsize=20)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "def Volume(df, out_dir, tag, output=False):\n",
    "    '''\n",
    "    Remove features that correlate with volume\n",
    "    df: dataframe with all feature values across treatment for one region\n",
    "    out_dir: output\n",
    "    tag: tag for output to denote any changes\n",
    "    output: print output\n",
    "    '''\n",
    "    # mask is constant so get volume for Fraction 1\n",
    "    df_vol = df[df[\"Fraction\"] == 1]\n",
    "    df_vol = df_vol[df_vol[\"Feature\"] == \"shape_MeshVolume\"]\n",
    "    vals_vol = df_vol[\"FeatureValue\"].values\n",
    "\n",
    "    fractions = df[\"Fraction\"].unique()\n",
    "    features = df[\"Feature\"].unique()\n",
    "\n",
    "    df_res = pd.DataFrame()\n",
    "\n",
    "    print(\"Tag: \" + tag)\n",
    "    print(\"Correlating features to volume...\")\n",
    "    for fr in fractions:\n",
    "        \n",
    "        for ft in tqdm(features):\n",
    "            # get feature values for each fraction\n",
    "            df_ft = df[df[\"Fraction\"] == fr]\n",
    "            df_ft = df_ft[df_ft[\"Feature\"] == ft]\n",
    "            vals_ft = df_ft[\"FeatureValue\"].values\n",
    "            # if vals are all the same, skip\n",
    "            if len(np.unique(vals_ft)) == 1:\n",
    "               rho = 1 \n",
    "\n",
    "            else:\n",
    "                # get spearman correlation\n",
    "                rho = stats.spearmanr(vals_vol, vals_ft)[0]\n",
    "\n",
    "            df_temp = pd.DataFrame({\"Fraction\": [fr], \"Feature\": [ft], \"rho\": [rho]})\n",
    "            df_res = df_res.append(df_temp)\n",
    "\n",
    "    # calculate mean rho for each feature\n",
    "    df_mean = df_res.groupby(\"Feature\").mean().reset_index()\n",
    "\n",
    "    # remove features\n",
    "    fts_remove = df_mean[abs(df_mean[\"rho\"]) > 0.6][\"Feature\"].values\n",
    "\n",
    "    if output == True:\n",
    "        print(\"\\nVolume redundant features: \" + str(len(fts_remove)) + \"/\" + str(len(features)) )\n",
    "        print(\"Remaining features: \" + str(len(df[\"Feature\"].unique()) - len(fts_remove)) + \"/\" + str(len(features)) + \"\\n\")\n",
    "    \n",
    "    fts_remove = pd.DataFrame({\"Feature\": fts_remove})\n",
    "    fts_remove.to_parquet(out_dir + \"/FeaturesRemoved_Volume_\" + tag + \".parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: dipl_Test\n",
      "Correlating features to volume...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 333.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 499.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 348.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 333.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 500.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Volume redundant features: 1/1\n",
      "Remaining features: 0/1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: normProstate_Test\n",
      "Correlating features to volume...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:00<00:00, 446.16it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 497.93it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 538.84it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 460.34it/s]\n",
      "100%|██████████| 107/107 [00:00<00:00, 480.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Volume redundant features: 17/107\n",
      "Remaining features: 90/107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outdir = out_root + \"/Test/\"\n",
    "Volume(df_dipl, outdir, \"dipl_Test\", True)\n",
    "Volume(df_normProstate, outdir, \"normProstate_Test\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def DistanceMatrix(df, outdir, tag, output=False):\n",
    "    '''\n",
    "    Calculates the Euclidean distance between feature pair trajectories\n",
    "    df: dataframe with all feature values across treatment for one region\n",
    "    out_dir: output\n",
    "    tag: tag for output to denote any changes\n",
    "    output: print output\n",
    "    '''\n",
    "    \n",
    "    features = df[\"Feature\"].unique()\n",
    "    PatIDs = df[\"PatID\"].unique()\n",
    "\n",
    "    df_res = pd.DataFrame()\n",
    "\n",
    "    print(\"Tag: \" + tag)\n",
    "    print(\"Calculating Euclidean distance between feature pair trajectories...\")\n",
    "\n",
    "    if os.path.isdir(outdir + \"/DM/\") == False:\n",
    "        os.mkdir(outdir + \"/DM/\")\n",
    "        os.mkdir(outdir + \"/DM/data/\")\n",
    "        os.mkdir(outdir + \"/DM/figs/\")\n",
    "    \n",
    "    for pat in tqdm(PatIDs):\n",
    "        df_pat = df[df[\"PatID\"] == pat]\n",
    "\n",
    "        matrix = np.zeros((len(features), len(features)))\n",
    "\n",
    "        for i, ft1 in enumerate(features):\n",
    "            df_ft = df_pat[df_pat[\"Feature\"] == ft1]\n",
    "            vals1 = df_ft[\"FeatureValue\"].values\n",
    "            if vals1[0] == 0:\n",
    "                vals1[0] = 1\n",
    "            vals1_ch = (vals1 - vals1[0]) / vals1[0]\n",
    "            for j, ft2 in enumerate(features):\n",
    "                df_ft2 = df_pat[df_pat[\"Feature\"] == ft2]\n",
    "                vals2 = df_ft2[\"FeatureValue\"].values\n",
    "                if vals2[0] == 0:\n",
    "                    vals2[0] = 1\n",
    "                \n",
    "                vals2_ch = (vals2 - vals2[0]) / vals2[0]\n",
    "                \n",
    "\n",
    "                # get euclidean distance\n",
    "                # fill nan with 0\n",
    "                if np.isnan(vals1_ch).any() == True:\n",
    "                    print(pat)\n",
    "                    print(ft1, vals1)\n",
    "                if np.isnan(vals2_ch).any() == True:\n",
    "                    print(pat)\n",
    "                    print(ft2, vals2)\n",
    "                \n",
    "                matrix[i,j] = distance.euclidean(vals1_ch, vals2_ch)\n",
    "    \n",
    "        df_dist = pd.DataFrame(matrix, columns=features, index=features)\n",
    "        df_dist.to_parquet(outdir + \"/DM/data/\" + pat + \"_\" + tag + \".parquet\")\n",
    "\n",
    "        if output == True:\n",
    "            plt.figure(figsize=(10,10))\n",
    "            sns.heatmap(df_dist, cmap=\"viridis\")\n",
    "            plt.title(\"{} - {}\".format(pat, tag), fontsize=20)\n",
    "            # make sure all ticks show\n",
    "            plt.xticks(np.arange(len(features)) + 0.5, features, fontsize=6)\n",
    "            plt.yticks(np.arange(len(features)) + 0.5, features, fontsize=6)\n",
    "            \n",
    "\n",
    "            plt.savefig(outdir + \"/DM/figs/\" + pat + \"_\" + tag + \".png\")\n",
    "            plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: dipl_Test\n",
      "Calculating Euclidean distance between feature pair trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [04:20<00:00, 13.71s/it]\n"
     ]
    }
   ],
   "source": [
    "outdir = out_root + \"/Test/\"\n",
    "volume_fts = pd.read_parquet(outdir + \"/FeaturesRemoved_Volume_dipl_Test.parquet\")[\"Feature\"].values\n",
    "df_dipl = df_SABR[df_SABR[\"Region\"] == \"dipl\"]\n",
    "df_dipl = df_dipl[~df_dipl[\"Feature\"].isin(volume_fts)]\n",
    "df_dipl = df_dipl[df_dipl[\"Feature\"] != \"firstorder_Minimum\"]\n",
    "DistanceMatrix(df_dipl, outdir, \"dipl_Test\", False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: normProstate_Test\n",
      "Calculating Euclidean distance between feature pair trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [03:09<00:00,  9.96s/it]\n"
     ]
    }
   ],
   "source": [
    "volume_fts = pd.read_parquet(outdir + \"/FeaturesRemoved_Volume_normProstate_Test.parquet\")[\"Feature\"].values\n",
    "df_norm = df_SABR[df_SABR[\"Region\"] == \"normProstate\"]\n",
    "df_norm = df_norm[~df_norm[\"Feature\"].isin(volume_fts)]\n",
    "df_norm = df_norm[df_norm[\"Feature\"] != \"firstorder_Minimum\"]\n",
    "DistanceMatrix(df_norm, outdir, \"normProstate_Test\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def ClusterCheck(df, fts, t_val, tries, df_DM):\n",
    "        '''\n",
    "        If cluster has more than 10 features, re-cluster with smaller t_val\n",
    "        '''\n",
    "        df_c = df\n",
    "        df_new = pd.DataFrame()\n",
    "        # feature names\n",
    "        df_new[\"FeatureName\"] = fts\n",
    "        # cluster labels\n",
    "        c = df_c[\"Cluster\"].values[0]\n",
    "        \n",
    "        # need to filter distance matrix to only include features in cluster\n",
    "        df_DM_c = df_DM[fts]\n",
    "        # only keep features in cluster\n",
    "        df_DM_c = df_DM_c[df_DM_c.index.isin(fts)]\n",
    "        \n",
    "        # convert to numpy array\n",
    "        arr_DM_c = df_DM_c.to_numpy()\n",
    "        \n",
    "        # cluster\n",
    "        df_new[\"Cluster\"] = spch.fclusterdata(arr_DM_c, t=t_val, criterion=\"distance\", method=\"ward\")\n",
    "        df_new[\"Cluster\"] = str(c*100) + str(tries) + df_new[\"Cluster\"].astype(str)\n",
    "        df_new[\"Cluster\"] = df_new[\"Cluster\"].astype(int)\n",
    "        df_new[\"NumFts\"] = df_new.groupby(\"Cluster\")[\"Cluster\"].transform(\"count\")\n",
    "        number_fts = df_new[\"NumFts\"].unique()\n",
    "        fts_check = df_new.loc[df_new[\"NumFts\"] > 10][\"FeatureName\"].values\n",
    "        #print(t_val, number_fts)#, df_new)\n",
    "        return number_fts, df_new, fts_check\n",
    "\n",
    "####################################################\n",
    "\n",
    "def ClusterFeatures(DataRoot, Norm, s_t_val, tag):\n",
    "    '''\n",
    "    Cluster features using distance matrix, \n",
    "    t_val is threshold for clustering, \n",
    "    method is clustering forumula\n",
    "    performs clustering until all clusters have less than 10 features\n",
    "    '''\n",
    "    root = DataRoot\n",
    "    DM_dir = root + \"\\\\Aaron\\\\ProstateMRL\\\\Data\\\\Paper1\\\\\" + Norm + \"\\\\Longitudinal\\\\DM\\\\csvs\\\\\"\n",
    "    out_dir = root + \"\\\\Aaron\\\\ProstateMRL\\\\Data\\\\Paper1\\\\\"+ Norm + \"\\\\Longitudinal\\\\ClusterLabels\\\\\"\n",
    "\n",
    "    # patIDs = UF.SABRPats()\n",
    "\n",
    "    cluster_method = \"weighted\"\n",
    "    patIDs = df_all[\"PatID\"].unique()\n",
    "\n",
    "    for pat in tqdm(patIDs):\n",
    "        df_DM = pd.read_csv(DM_dir + pat + \"_\" + tag + \".csv\")\n",
    "        df_DM.set_index(\"Unnamed: 0\", inplace=True)\n",
    "        arr_DM = df_DM.to_numpy()\n",
    "        fts = df_DM.columns\n",
    "\n",
    "        # create temp df to hold ft name and label\n",
    "        df_labels = pd.DataFrame()\n",
    "        df_labels[\"FeatureName\"] = fts\n",
    "\n",
    "        # cluster function using DM, need to experiment with t_val and method\n",
    "        df_labels[\"Cluster\"] = spch.fclusterdata(arr_DM, t=s_t_val, criterion=\"distance\", method=cluster_method)\n",
    "        df_labels.set_index(\"FeatureName\", inplace=True)\n",
    "        \n",
    "        # check number of features in each cluster\n",
    "        df_labels[\"NumFts\"] = df_labels.groupby(\"Cluster\")[\"Cluster\"].transform(\"count\")\n",
    "        df_labels[\"Cluster\"] = df_labels[\"Cluster\"].astype(int)\n",
    "        #print(\"---------------------------\")\n",
    "        #print(\"Patient: {}\".format(pat))\n",
    "        #print(df_labels.loc[df_labels[\"NumFts\"] > 10])\n",
    "        # loop through clusters \n",
    "        for c in df_labels[\"Cluster\"].unique():\n",
    "                df_c = df_labels[df_labels[\"Cluster\"] == c]\n",
    "                number_fts = len(df_c)\n",
    "                # check numnber of features in cluster\n",
    "                if number_fts > 10:\n",
    "                        # if more than 10 features in cluster, reduce t_val and recluster\n",
    "                        t_val = s_t_val - 0.2\n",
    "                        check_fts = df_c.index.values\n",
    "                        tries = 1\n",
    "                        number_fts, df_labels2, check_fts = ClusterCheck(df_c, check_fts, t_val, tries, df_DM)\n",
    "                        new_fts = df_labels2[\"FeatureName\"].unique()\n",
    "                        df_labels.loc[new_fts, \"Cluster\"] = df_labels2[\"Cluster\"].values\n",
    "                        df_labels[\"NumFts\"] = df_labels.groupby(\"Cluster\")[\"Cluster\"].transform(\"count\")\n",
    "\n",
    "                        while number_fts.max() > 10:\n",
    "                                t_val = t_val - 0.2\n",
    "                                tries += 1\n",
    "                                #print(\"Cluster: {} Tries: {} T_val: {}\".format(c, tries, t_val))\n",
    "                                number_fts, df_labels2, check_fts = ClusterCheck(df_c, check_fts, t_val, tries, df_DM)\n",
    "                                new_fts = df_labels2[\"FeatureName\"].unique()\n",
    "                                df_labels.loc[new_fts, \"Cluster\"] = df_labels2[\"Cluster\"].values\n",
    "                        \n",
    "        df_labels[\"NumFts\"] = df_labels.groupby(\"Cluster\")[\"Cluster\"].transform(\"count\")\n",
    "\n",
    "        # read in df with ft vals and merge\n",
    "        ft_vals = pd.read_csv(root +\"Aaron\\\\ProstateMRL\\\\Data\\\\Paper1\\\\\"+ Norm + \"\\\\Features\\\\Longitudinal_All_fts_\" + tag + \".csv\")\n",
    "        ft_vals[\"PatID\"] = ft_vals[\"PatID\"].astype(str)\n",
    "        pat_ft_vals = ft_vals[ft_vals[\"PatID\"] == pat]\n",
    "        pat_ft_vals = pat_ft_vals.merge(df_labels, left_on=\"Feature\", right_on=\"FeatureName\")\n",
    "\n",
    "        # output is feature values w/ cluster labels\n",
    "        pat_ft_vals.to_csv(out_dir + pat + \"_\" + tag + \".csv\")\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClusterCC(Cluster_ft_df):\n",
    "    '''\n",
    "    Input - df filtered for norm, patient, cluster\n",
    "    Output - performs cross-correlation within clustered fts and returns ft most strongly correlated with the rest, if more than 2 fts present\n",
    "    '''\n",
    "    fts = Cluster_ft_df.Feature.unique()\n",
    "    num_fts = len(fts)\n",
    "   \n",
    "    if num_fts > 2:\n",
    "        vals = {} # stores fts and values\n",
    "        ccfs = {} # stores cc values for each feature\n",
    "        mean_ccfs = {} # stores the mean cc value for every feature\n",
    "        num_sel = np.rint(len(fts) * 0.2)\n",
    "        \n",
    "        for f in fts:\n",
    "            ft_df = Cluster_ft_df[Cluster_ft_df[\"Feature\"] == f]\n",
    "            ft_vals = ft_df.FeatureChange.values\n",
    "            vals[f] = ft_vals\n",
    "        \n",
    "        for v in vals:\n",
    "            ft_1 = vals[v]\n",
    "            ccfs[v] = v\n",
    "            ccfs_vals = []\n",
    "\n",
    "            for u in vals:\n",
    "                ft_2 = vals[u]\n",
    "                corr = sts.ccf(ft_1, ft_2)[0] # cross correlation value, index [0] for for 0 lag in csc function\n",
    "                ccfs_vals.append(corr)\n",
    "            \n",
    "            mean_ccfs[v] = np.array(ccfs_vals).mean() # get mean across all cc values for each ft\n",
    "\n",
    "        s_mean_ccfs = sorted(mean_ccfs.items(), key=lambda x:x[1], reverse=True)\n",
    "        sorted_temp = s_mean_ccfs[0:int(num_sel)]\n",
    "        ft_selected = [seq[0] for seq in sorted_temp]\n",
    "\n",
    "    else: \n",
    "        ft_selected = 0\n",
    "\n",
    "    return ft_selected\n",
    "\n",
    "####################################################\n",
    "\n",
    "def ClusterSelection(DataRoot, Norm, tag, output):\n",
    "    '''\n",
    "    Loops through each patient  to select the 'best' feature for each cluster by performing cross-correlation\n",
    "    Discards clusters with less than 3 features\n",
    "    Selects features which are ranked in top 10 across all patients\n",
    "    '''\n",
    "    root = DataRoot\n",
    "    patIDs = UF.SABRPats()\n",
    "\n",
    "    labels_dir = root + \"\\\\Aaron\\\\ProstateMRL\\\\Data\\\\Paper1\\\\\" + Norm + \"\\\\Longitudinal\\\\ClusterLabels\\\\\"\n",
    "    out_dir = root + \"\\\\Aaron\\\\ProstateMRL\\\\Data\\\\Paper1\\\\\"+ Norm +\"\\\\Features\\\\\"\n",
    "    \n",
    "    df_result = pd.DataFrame()\n",
    "    for pat in tqdm(patIDs):\n",
    "        # read in feature vals and associated cluster labels\n",
    "        df_pat = pd.read_csv(labels_dir + pat + \"_\" + tag + \".csv\")\n",
    "\n",
    "        cluster_num = df_pat[\"Cluster\"].unique()\n",
    "        fts_selected = []\n",
    "        df_result_pat = pd.DataFrame()\n",
    "\n",
    "        # for each patient loop through each cluster to get 'best' feature\n",
    "        for c in cluster_num:\n",
    "            df_cluster = df_pat[df_pat[\"Cluster\"] == c]\n",
    "\n",
    "            # function loops through each cluster and gets feature values\n",
    "            # performs cross-correlation and returns feature with highest mean correlation to all other features\n",
    "            # returns NULL if < 3 features in cluster \n",
    "            ft_selected = ClusterCC(df_cluster)\n",
    "\n",
    "            if ft_selected != 0:\n",
    "                for f in ft_selected:\n",
    "                    fts_selected.append(f)\n",
    "        \n",
    "        # filter through all feature values and select only new features\n",
    "            row = {}\n",
    "\n",
    "        for f in fts_selected:\n",
    "            row[\"patID\"] = pat\n",
    "            row[\"Feature\"] = f\n",
    "            df_result_pat = df_result_pat.append(row, ignore_index=True)\n",
    "        \n",
    "        df_result = df_result.append(df_result_pat, ignore_index=True)\n",
    "\n",
    "    df_result = df_result.Feature.value_counts().rename_axis(\"Feature\").reset_index(name=\"Counts\")\n",
    "    # get number of counts at 10th row\n",
    "    counts = df_result.iloc[10][\"Counts\"]\n",
    "    #print(df_result)\n",
    "    # get features with counts >= counts\n",
    "    fts = df_result[df_result[\"Counts\"] >= counts][\"Feature\"].values\n",
    "    if output == True:\n",
    "        print(\"\\nSelected Features: ({})\".format(len(fts)))\n",
    "        for f in fts:\n",
    "            print(f)\n",
    "    df_result = df_result[df_result[\"Counts\"] >= counts]\n",
    "\n",
    "    # drop counts\n",
    "    df_result.drop(columns=[\"Counts\"], inplace=True)\n",
    "    df_result.to_csv(out_dir + \"Longitudinal_SelectedFeatures_\" + tag + \".csv\")\n",
    "\n",
    "####################################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PR-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
